# FastAPI Application

This application is a FastAPI server that uses the Llama model to answer questions. It receives a list of messages and parameters for the Llama model, then returns the model's response.

## Prerequisites

- Python 3.6 or higher
- FastAPI
- Uvicorn (for running the FastAPI server)
- Llama C++ model
- OpenAI
- Pydantic

## Setup

1. Clone this repository to your local machine.
2. Navigate to the project directory.

```bash
cd path_to_your_directory
